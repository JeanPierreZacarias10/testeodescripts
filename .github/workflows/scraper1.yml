name: Run Web Scraper

on:
  schedule:
    - cron: '42 17 * * *' # Ejecuta diariamente a las 12:25 PM hora peruana (5:25 PM UTC)
  workflow_dispatch: # Permite ejecutarlo manualmente desde la interfaz de GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        pip install selenium beautifulsoup4 pandas

    - name: Set up ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        sudo apt-get install -y chromium-browser

    - name: Run the scraper
      run: python Scriptslogicos/ScriptsEjecucon/scraper.py

    - name: Save results as artifact
      uses: actions/upload-artifact@v3
      with:
        name: scraping-results
        path: Scriptslogicos/archivosscripts/*.csv
