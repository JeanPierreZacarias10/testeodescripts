name: Run Web Scraper

on:
  schedule:
    - cron: '42 17 * * *' # Ejecuta diariamente a las 12:42 PM hora peruana (5:42 PM UTC)
  workflow_dispatch: # Permite ejecutarlo manualmente desde la interfaz de GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        pip install selenium beautifulsoup4 pandas

    - name: Set up ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        sudo apt-get install -y chromium-browser

    - name: List repository files
      run: ls -R # Lista todos los archivos en el repositorio para verificar rutas

    - name: Run scraper2.py
      run: python Scriptslogicos/ScriptsEjecucon/scraper2.py

    - name: Save results as artifact
      uses: actions/upload-artifact@v3
      with:
        name: scraping-results
        path: archivosscripts/*.csv
